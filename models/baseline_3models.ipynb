{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMa5OXplwqpAfw52zLOejlJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dany-xu/AI-Generated-Text-Detection-using-LLM/blob/main/models/baseline_3models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # current dir: '/content'\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from gensim.models import Word2Vec\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "q7K8udeHI458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f586910e-e032-4e1f-9997-a177e012615d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"./drive/MyDrive/ColabNotebooks/llm/concat_ori.csv\").drop(columns=[\"Unnamed: 0\"])\n",
        "data1 = data[data['label'] == 1]\n",
        "data0 = data[data['label'] == 0]\n",
        "train1, test1 = train_test_split(data1, test_size=0.2)\n",
        "train0, test0 = train_test_split(data0, test_size=0.2)\n",
        "train = pd.concat([train0, train1], ignore_index=True)\n",
        "test = pd.concat([test0, test1], ignore_index=True)\n",
        "train = train.loc[np.random.permutation(train.index)]\n",
        "test = test.loc[np.random.permutation(test.index)]\n",
        "train.shape, test.shape"
      ],
      "metadata": {
        "id": "S8PR3oy2I9M8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b4e9af-09d4-4a56-c43b-f8810a4df7b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40559, 5), (10140, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = list(train.abstract)\n",
        "train_label = list(train.label)\n",
        "test_data = list(test.abstract)\n",
        "test_label = list(test.label)"
      ],
      "metadata": {
        "id": "uXGpLGu6JRpY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag-of-Words (BoW) with Logistic Regression"
      ],
      "metadata": {
        "id": "gz6mBySIJasG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer()\n",
        "X_train_bow = vectorizer.fit_transform(train_data)\n",
        "X_test_bow = vectorizer.transform(test_data)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_bow, train_label)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test_bow)\n",
        "acc = accuracy_score(test_label, y_pred)\n",
        "print(f'Logistic Regression Accuracy: {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPufkgFkdlc_",
        "outputId": "ef99c89e-601f-4d6a-9952-6e0c229a4c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9064102564102564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMW6xxomIzOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9081f230-49ad-440d-9840-0b8beb02a986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9064102564102564\n",
            "Precision: 0.9037358549062161\n",
            "Recall: 0.9467359532315687\n",
            "F1-score: 0.9247362994686334\n",
            "Confusion Matrix: [[3361  621]\n",
            " [ 328 5830]]\n"
          ]
        }
      ],
      "source": [
        "# measure results\n",
        "accuracy = accuracy_score(test_label, y_pred)\n",
        "precision = precision_score(test_label, y_pred)\n",
        "recall = recall_score(test_label, y_pred)\n",
        "f1 = f1_score(test_label, y_pred)\n",
        "conf_matrix = confusion_matrix(test_label, y_pred) # confusion matrix\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\", conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N-gram Models with Naive Bayes"
      ],
      "metadata": {
        "id": "tAUqsIB7fExY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "X_train_ngram = vectorizer.fit_transform(train_data)\n",
        "X_test_ngram = vectorizer.transform(test_data)\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_ngram, train_label)\n",
        "\n",
        "y_pred_nb = nb_model.predict(X_test_ngram)\n",
        "acc_nb = accuracy_score(test_label, y_pred_nb)\n",
        "print(f'Naive Bayes Accuracy (N-grams): {acc_nb}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46t-Gbf6e9kA",
        "outputId": "abf3e4ea-d959-4460-c474-db1140ac641e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy (N-grams): 0.8787968441814595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# measure results\n",
        "accuracy = accuracy_score(test_label, y_pred_nb)\n",
        "precision = precision_score(test_label, y_pred_nb)\n",
        "recall = recall_score(test_label, y_pred_nb)\n",
        "f1 = f1_score(test_label, y_pred_nb)\n",
        "conf_matrix = confusion_matrix(test_label, y_pred_nb) # confusion matrix\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\", conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmsAS1a2fkz9",
        "outputId": "f2148470-7584-4afc-cc7c-b3ace599bfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8787968441814595\n",
            "Precision: 0.872449750642285\n",
            "Recall: 0.9374797012016889\n",
            "F1-score: 0.9037964774951076\n",
            "Confusion Matrix: [[3138  844]\n",
            " [ 385 5773]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Embeddings with SVM"
      ],
      "metadata": {
        "id": "mGocU2t3fhEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = list(data.abstract) # tokenize\n",
        "tokens = [word for sentence in text_data for word in sentence.lower().split()]\n",
        "token_counts = Counter(tokens)# frequency\n",
        "num_unique_tokens = len(token_counts)\n",
        "max_features = int(num_unique_tokens * 1.1) # set max_features slightly higher\n",
        "\n",
        "print(\"unique token num:\", num_unique_tokens)\n",
        "print(\"my max_features:\", max_features)"
      ],
      "metadata": {
        "id": "hox1DX8djxDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f516b4a6-46f4-4bbf-955f-b57583117b0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique token num: 107263\n",
            "my max_features: 117989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=50)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_data)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_data)\n",
        "\n",
        "svm_classifier = SVC(kernel='linear')  # linear kernel for SVM\n",
        "svm_classifier.fit(X_train_tfidf, train_label)\n",
        "y_pred = svm_classifier.predict(X_test_tfidf)\n",
        "\n",
        "acc = accuracy_score(test_label, y_pred)\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaNkbwprfxT8",
        "outputId": "97074fc4-c012-4f61-8f7d-d0d504c24ef9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7971400394477317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# measure results\n",
        "accuracy = accuracy_score(test_label, y_pred)\n",
        "precision = precision_score(test_label, y_pred)\n",
        "recall = recall_score(test_label, y_pred)\n",
        "f1 = f1_score(test_label, y_pred)\n",
        "conf_matrix = confusion_matrix(test_label, y_pred) # confusion matrix\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)\n",
        "print(\"Confusion Matrix:\", conf_matrix)"
      ],
      "metadata": {
        "id": "kHoWuOpBlI58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44937807-beb6-4b5c-cb30-f00db8b92c26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7971400394477317\n",
            "Precision: 0.8060904612628751\n",
            "Recall: 0.8769080870412471\n",
            "F1-score: 0.8400093334370383\n",
            "Confusion Matrix: [[2683 1299]\n",
            " [ 758 5400]]\n"
          ]
        }
      ]
    }
  ]
}